{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CME538 - Introduction to Data Science\n",
    "## Lecture 3.2 - Importing Data from Different Sources\n",
    "\n",
    "### Lecture Structure\n",
    "1. [Structured Text Data](#section1)\n",
    "2. [Unstructured Text Data](#section2)\n",
    "3. [JSON](#section3)\n",
    "4. [XML](#section4)\n",
    "5. [HDF5](#section5)\n",
    "6. [API](#section6)\n",
    "7. [HTML](#section7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import 3rd party libraries\n",
    "import os\n",
    "import json \n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Configure Notebook\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')\n",
    "sns.set_context(\"notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install and Import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section1'></a>\n",
    "## 1. Structured Text Data\n",
    "Text files are human readable, in contrast to binary files, and can be opened using any text editor (Notepad, Sublime, etc.). Tabular (structured) data that is stored as a text file is often delimited using commas `,`, tabs `\\t`, spaces ` `, or pipes `|`. As long as its consistent, any character can be used to delimit a text file. These characters are used to delimit the different columns (fields) in a table. And rows are delimited by a `\\n` at the end of each row.\n",
    "\n",
    "### Comma-Separated Values (CSV)\n",
    "Let's try opening a `.csv`. This file contains 38765 rows of purchase orders from people at a grocery store. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groceries = open('groceries_dataset.csv', 'r')\n",
    "groceries.read()[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groceries = pd.read_csv('groceries_dataset.csv')\n",
    "groceries.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tab-Separated Values (TSV)\n",
    "Let's try opening a `.tsv`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groceries = open('groceries_dataset.tsv', 'r')\n",
    "groceries.read()[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groceries = pd.read_csv('groceries_dataset.tsv', sep='\\t')\n",
    "groceries.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipe-Separated Values (PSV) ??\n",
    "Let's try opening a `.psv` (I just made this up). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groceries = open('groceries_dataset.psv', 'r')\n",
    "groceries.read()[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groceries = pd.read_csv('groceries_dataset.psv', sep='|')\n",
    "groceries.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the time, you'll be dealing with `.csv` files when working with tabular files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section2'></a>\n",
    "## 2. Unstructured Text Data\n",
    "The [NOAA - Great Lakes Environmental Research Laboratory](https://www.glerl.noaa.gov/res/glcfs/) (GLERL) dataset contains forecasts and measurements for Ice Cover, Wave Height, Current Direction, Wind Speed, and others. \n",
    "<br>\n",
    "<img src=\"images/noaa.gif\" alt=\"drawing\" width=\"700\"/>\n",
    "<br>\n",
    "The file is human readable, however, it is not tabular and therefore, cannot be easily imported into a Pandas DataFrame. Don't believe me? Let's give it a try.\n",
    "\n",
    "First, let's take a look at the file in a text editor. I recommend using [Sublime](https://www.sublimetext.com/). From the text editor, we can see that the fields seems to be delimited by tabs or spaces so lets used `.read_csv` to import our file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noaa = pd.read_csv('e202027712.0.wav', sep='\\t')\n",
    "noaa.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something doesn't look right here. Let's try opening the file using the `open()` function which returns a file object, which has helpful methods (`.read()`, `.readline()`) for reading the content of the file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "noaa = open('e202027712.0.wav', 'r')\n",
    "print(noaa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the `noaa` variable is a file object. The file class hass a method for reading one line of a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(noaa.readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(noaa.readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(noaa.readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(noaa.readline())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use `.readline()` in a `for` loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(10):\n",
    "    print(noaa.readline())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to return to the beginning of the file, we must open the file again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noaa = open('e202027712.0.wav', 'r')\n",
    "for _ in range(10):\n",
    "    print(noaa.readline())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.read()` method, on the other hand, reads the file as an individual string, and allows for relatively easy file-wide manipulations. Below, lets display the first 1000 characters from the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "noaa = open('e202027712.0.wav', 'r')\n",
    "noaa.read()[0:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now lets print the first 1000 characters from the file, which created a new line from `\\n` newline character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noaa = open('e202027712.0.wav', 'r')\n",
    "print(noaa.read()[0:1000])\n",
    "noaa.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section3'></a>\n",
    "## 3. JSON\n",
    "JavaScript Object Notation (JSON) is a lightweight data format that easy for humans to read and write. JSON is easy for machines to parse and generate and is based on the JavaScript Programming Language Standard. JSON is a text format that is programming language independent and can be early parsed using Python, Ruby, Pearl and many others.\n",
    "\n",
    "JSON is built on two structures:\n",
    "\n",
    "1. A collection of name/value pairs. This is realized as an object, record, dictionary, hash table, keyed list, or associative array.\n",
    "2. An ordered list of values. This is realized as an array, vector, list, or sequence.\n",
    "\n",
    "There are several third party packages that can be used to program with JSON files, however, Python includes a native package `json`, which we imported at the start of this notebook.\n",
    "\n",
    "```python\n",
    "import json\n",
    "```\n",
    "\n",
    "The JSON format is used primarily to transmit data between a server and web application, which we'll see more of in Section 7 [API](#section7) and 8 [HTML](#section8). As as example, we'll be working with the [Twitter](https://twitter.com/) JSON structure for tweets. \n",
    "\n",
    "Let's take a look at the Twitter tweet below,\n",
    "<br>\n",
    "<img src=\"images/tweet.png\" alt=\"drawing\" width=\"500\"/>\n",
    "<br>\n",
    "and the associated JSON file.\n",
    "```json\n",
    "{\n",
    "  \"created_at\": \"Thu Apr 06 15:24:15 +0000 2017\",\n",
    "  \"id_str\": \"850006245121695744\",\n",
    "  \"text\": \"1\\/ Today we\\u2019re sharing our vision for the future of the Twitter API platform!\\nhttps:\\/\\/t.co\\/XweGngmxlP\",\n",
    "  \"user\": {\n",
    "    \"id\": 2244994945,\n",
    "    \"name\": \"Twitter Dev\",\n",
    "    \"screen_name\": \"TwitterDev\",\n",
    "    \"location\": \"Internet\",\n",
    "    \"url\": \"https:\\/\\/dev.twitter.com\\/\",\n",
    "    \"description\": \"Your official source for Twitter Platform news, updates & events. Need technical help? Visit https:\\/\\/twittercommunity.com\\/ \\u2328\\ufe0f #TapIntoTwitter\"\n",
    "  },\n",
    "  \"place\": {   \n",
    "  },\n",
    "  \"entities\": {\n",
    "    \"hashtags\": [      \n",
    "    ],\n",
    "    \"urls\": [\n",
    "      {\n",
    "        \"url\": \"https:\\/\\/t.co\\/XweGngmxlP\",\n",
    "        \"unwound\": {\n",
    "          \"url\": \"https:\\/\\/cards.twitter.com\\/cards\\/18ce53wgo4h\\/3xo1c\",\n",
    "          \"title\": \"Building the Future of the Twitter API Platform\"\n",
    "        }\n",
    "      }\n",
    "    ],\n",
    "    \"user_mentions\": [     \n",
    "    ]\n",
    "  }\n",
    "}\n",
    "```\n",
    "You'll notice that the data structure is very similar to Python Dictionaries. \n",
    "\n",
    "#### Import\n",
    "First, let's learn how to load a JSON file into Python as a Dictionary. There are two methods for parsing JSON, `json.load()` and `json.loads()`. \n",
    "\n",
    "**`json.load()`** can deserialize a file (it accepts a file object)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = json.load(open('tweet.json'))\n",
    "tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is a useful function for printing JSONs with the correct indentation to improve readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_print(obj):\n",
    "    text = json.dumps(obj, sort_keys=True, indent=4)\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_print(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable `tweet` is now a Python Dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`json.loads()`** deserializes a string (the `s` stands for String - \"load string\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_string = '{\"name\": \"Sebastian\", \"age\": 35}'\n",
    "json_dict = json.loads(json_string)\n",
    "json_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save\n",
    "Like with importing JSONs, there are two functions for saving JSON files, `json.dump()` and `json.dumps()`.\n",
    "\n",
    "**`json.dump()`** is used to write Python serialized object as JSON formatted data into a file. For example, if we take the `tweet` dictionary, we can save it to a file using `json.dump()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_file.json', 'w') as f:\n",
    "    json.dump(tweet, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`json.dumps()`** encodes any Python object into JSON formatted String. For example, if we take the `tweet` dictionary, we can save it to a string using `json.dumps()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_string = json.dumps(tweet)\n",
    "json_string "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although they appear similar, there are some important differences between Python Dictionaries and JSONs.\n",
    "\n",
    "| Python  | JSON   |\n",
    "|---------|--------|\n",
    "|dict\t  | Object | \n",
    "|list\t  | Array  | \n",
    "|tuple\t  | Array  |\n",
    "|str\t  | String |\n",
    "|int\t  | Number |\n",
    "|float\t  | Number |\n",
    "|True\t  | true   |\n",
    "|False\t  | false  |\n",
    "|None\t  | null   |\n",
    "\n",
    "For example, this means that you cannot include a tuple or a list in a JSON. They will both be incoded as an array. Similarly, you cannot encode a NumPy array in a JSON. Let's give it a try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = {'counts': np.array([0, 5, 4, 10, 45])} \n",
    "json_string = json.dumps(sample_data)\n",
    "json_string "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can learn more about the JSONs by visiting its official [page](https://docs.python.org/3.6/library/json.html) on the Python website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section4'></a>\n",
    "## 4. XML\n",
    "Extensible Markup Language (XML) is a markup language that defines a set of rules for encoding documents in a format that is both human-readable and machine-readable. XML is similar to HTML. Python contains a native module for reading XML which we imported at the start of the notebook.\n",
    "```python\n",
    "import xml.etree.ElementTree as ET\n",
    "```\n",
    "Below is an example of the XML file structure containing the names of employees at a company.\n",
    "```xml\n",
    "<employees>\n",
    "  <employee>\n",
    "    <firstName>John</firstName> <lastName>Doe</lastName>\n",
    "  </employee>\n",
    "  <employee>\n",
    "    <firstName>Anna</firstName> <lastName>Smith</lastName>\n",
    "  </employee>\n",
    "  <employee>\n",
    "    <firstName>Peter</firstName> <lastName>Jones</lastName>\n",
    "  </employee>\n",
    "</employees>\n",
    "```\n",
    "Let's try importing a sample XML file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = ET.parse('books.xml')\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file we opened `books.xml` looks like this.\n",
    "```xml\n",
    "<catalog>\n",
    "   <book id=\"bk101\">\n",
    "      <author>Gambardella, Matthew</author>\n",
    "      <title>XML Developer's Guide</title>\n",
    "      <genre>Computer</genre>\n",
    "      <price>44.95</price>\n",
    "      <publish_date>2000-10-01</publish_date>\n",
    "      <description>An in-depth look at creating applications \n",
    "      with XML.</description>\n",
    "   </book>\n",
    "   <book id=\"bk102\">\n",
    "      <author>Ralls, Kim</author>\n",
    "      <title>Midnight Rain</title>\n",
    "      <genre>Fantasy</genre>\n",
    "      <price>5.95</price>\n",
    "      <publish_date>2000-12-16</publish_date>\n",
    "      <description>A former architect battles corporate zombies, \n",
    "      an evil sorceress, and her own childhood to become queen \n",
    "      of the world.</description>\n",
    "   </book>\n",
    "   <book id=\"bk103\">\n",
    "      <author>Corets, Eva</author>\n",
    "      <title>Maeve Ascendant</title>\n",
    "      <genre>Fantasy</genre>\n",
    "      <price>5.95</price>\n",
    "      <publish_date>2000-11-17</publish_date>\n",
    "      <description>After the collapse of a nanotechnology \n",
    "      society in England, the young survivors lay the \n",
    "      foundation for a new society.</description>\n",
    "   </book>\n",
    "   <book id=\"bk104\">\n",
    "      <author>Corets, Eva</author>\n",
    "      <title>Oberon's Legacy</title>\n",
    "      <genre>Fantasy</genre>\n",
    "      <price>5.95</price>\n",
    "      <publish_date>2001-03-10</publish_date>\n",
    "      <description>In post-apocalypse England, the mysterious \n",
    "      agent known only as Oberon helps to create a new life \n",
    "      for the inhabitants of London. Sequel to Maeve \n",
    "      Ascendant.</description>\n",
    "   </book>\n",
    "   <book id=\"bk105\">\n",
    "      <author>Corets, Eva</author>\n",
    "      <title>The Sundered Grail</title>\n",
    "      <genre>Fantasy</genre>\n",
    "      <price>5.95</price>\n",
    "      <publish_date>2001-09-10</publish_date>\n",
    "      <description>The two daughters of Maeve, half-sisters, \n",
    "      battle one another for control of England. Sequel to \n",
    "      Oberon's Legacy.</description>\n",
    "   </book>\n",
    "   <book id=\"bk106\">\n",
    "      <author>Randall, Cynthia</author>\n",
    "      <title>Lover Birds</title>\n",
    "      <genre>Romance</genre>\n",
    "      <price>4.95</price>\n",
    "      <publish_date>2000-09-02</publish_date>\n",
    "      <description>When Carla meets Paul at an ornithology \n",
    "      conference, tempers fly as feathers get ruffled.</description>\n",
    "   </book>\n",
    "   <book id=\"bk107\">\n",
    "      <author>Thurman, Paula</author>\n",
    "      <title>Splish Splash</title>\n",
    "      <genre>Romance</genre>\n",
    "      <price>4.95</price>\n",
    "      <publish_date>2000-11-02</publish_date>\n",
    "      <description>A deep sea diver finds true love twenty \n",
    "      thousand leagues beneath the sea.</description>\n",
    "   </book>\n",
    "   <book id=\"bk108\">\n",
    "      <author>Knorr, Stefan</author>\n",
    "      <title>Creepy Crawlies</title>\n",
    "      <genre>Horror</genre>\n",
    "      <price>4.95</price>\n",
    "      <publish_date>2000-12-06</publish_date>\n",
    "      <description>An anthology of horror stories about roaches,\n",
    "      centipedes, scorpions  and other insects.</description>\n",
    "   </book>\n",
    "   <book id=\"bk109\">\n",
    "      <author>Kress, Peter</author>\n",
    "      <title>Paradox Lost</title>\n",
    "      <genre>Science Fiction</genre>\n",
    "      <price>6.95</price>\n",
    "      <publish_date>2000-11-02</publish_date>\n",
    "      <description>After an inadvertant trip through a Heisenberg\n",
    "      Uncertainty Device, James Salway discovers the problems \n",
    "      of being quantum.</description>\n",
    "   </book>\n",
    "   <book id=\"bk110\">\n",
    "      <author>O'Brien, Tim</author>\n",
    "      <title>Microsoft .NET: The Programming Bible</title>\n",
    "      <genre>Computer</genre>\n",
    "      <price>36.95</price>\n",
    "      <publish_date>2000-12-09</publish_date>\n",
    "      <description>Microsoft's .NET initiative is explored in \n",
    "      detail in this deep programmer's reference.</description>\n",
    "   </book>\n",
    "   <book id=\"bk111\">\n",
    "      <author>O'Brien, Tim</author>\n",
    "      <title>MSXML3: A Comprehensive Guide</title>\n",
    "      <genre>Computer</genre>\n",
    "      <price>36.95</price>\n",
    "      <publish_date>2000-12-01</publish_date>\n",
    "      <description>The Microsoft MSXML3 parser is covered in \n",
    "      detail, with attention to XML DOM interfaces, XSLT processing, \n",
    "      SAX and more.</description>\n",
    "   </book>\n",
    "   <book id=\"bk112\">\n",
    "      <author>Galos, Mike</author>\n",
    "      <title>Visual Studio 7: A Comprehensive Guide</title>\n",
    "      <genre>Computer</genre>\n",
    "      <price>49.95</price>\n",
    "      <publish_date>2001-04-16</publish_date>\n",
    "      <description>Microsoft Visual Studio 7 is explored in depth,\n",
    "      looking at how Visual Basic, Visual C++, C#, and ASP+ are \n",
    "      integrated into a comprehensive development \n",
    "      environment.</description>\n",
    "   </book>\n",
    "</catalog>\n",
    "```\n",
    "From the root of the XML tree, we can get all children, which should correspond to the 12 book tags we see. be can use the Python `list()` operator to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for book in list(root):\n",
    "    print(book.tag, book.attrib)\n",
    "    print(book.find('author').text)\n",
    "    print(book.find('title').text)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JSON and XML are similar in some ways\n",
    "\n",
    "- Both JSON and XML are \"self describing\" (human readable)\n",
    "- Both JSON and XML are hierarchical (values within values)\n",
    "- Both JSON and XML can be parsed and used by lots of programming languages\n",
    "- Both JSON and XML can be fetched with an XMLHttpRequest\n",
    "\n",
    "and different in other ways.\n",
    "\n",
    "- JSON doesn't use end tag\n",
    "- JSON is shorter\n",
    "- JSON is quicker to read and write\n",
    "- JSON can use arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section5'></a>\n",
    "## 5. Hierarchical Data Format (HDF)\n",
    "Hierarchical Data Format (HDF) is a set of file formats (HDF4, HDF5) designed to store and organize large amounts of data. It was originally developed at the **National Center for Supercomputing Applications** and is now supported by [The HDF Group](https://www.hdfgroup.org/solutions/hdf5/), a non-profit corporation.\n",
    "<br>\n",
    "<img src=\"images/hdf5_structure4.jpg\" alt=\"drawing\" width=\"550\"/>\n",
    "<br>\n",
    "Let's see what the [The HDF Group](https://www.hdfgroup.org/solutions/hdf5/) says about the HDF5 file structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "'<iframe src=\"https://player.vimeo.com/video/226008481\" width=\"640\" height=\"360\" frameborder=\"0\" allow=\"autoplay; fullscreen\" allowfullscreen></iframe>'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Python package [h5py](https://www.h5py.org/) is required for working with HFD5 files. You'll see we installed and imported that package at the start of the Notebook.\n",
    "\n",
    "```python\n",
    "!pip install h5py\n",
    "\n",
    "import h5py\n",
    "```\n",
    "\n",
    "For working exploring the HDF5 file structure, we'll be working with Hyperspectral Imagery data which is a dataset that Civil & Mineral Engineers might run into. \n",
    "<br>\n",
    "<img src=\"images/light_spectrum.jpg\" alt=\"drawing\" width=\"800\"/>\n",
    "<br>\n",
    "Hyperspectral imaging collects information from across the electromagnetic spectrum, which can be seen in the image below. Most familiar to us is the visible light spectrum ranging from red (700 nanometers) to violet (380 nanometers). Hyperspectral imagery is acquired in the infrared spectrum typically between 400 and 1100 nanometers.    \n",
    "<br>\n",
    "<img src=\"images/hyperspectral_image.png\" alt=\"drawing\" width=\"900\"/>\n",
    "<br>\n",
    "A typical JPEG image that you might capture with your smartphone will have three color channels (Red, Green, and Blue). So, if your image is 500 pixels x 500 pixels (spatial dimensions), there will be a 3rd dimension of size three (3 color challanges). When imported into Python as an array, the shape of the array would be (500, 500, 3). With hyperspectral imagery, you're acquiring a continuous spectrum and thus, each pixel contains many more than three values as displayed in the image above. \n",
    "\n",
    "Let's use [h5py](https://www.h5py.org/) to import a hyperspectral image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperspec = h5py.File('NEON_hyperspectral_dataset.h5', mode='r') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, lets see what groups are inside the file object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hyperspec.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and what groups are inside that group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hyperspec['SJER'].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and what groups are inside that group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hyperspec['SJER']['Reflectance'].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and what groups are inside the Metadata group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hyperspec['SJER']['Reflectance']['Metadata'].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You're starting to get the picture right? HDF5 is just a hierarchical folder structure as the name suggests.\n",
    "\n",
    "Quick tip: We can make the same call as above using the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hyperspec['SJER/Reflectance/Metadata'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hyperspectral_data():\n",
    "    hyperspec = h5py.File('NEON_hyperspectral_dataset.h5', mode='r') \n",
    "    sjer_reflectance = hyperspec['SJER']['Reflectance']\n",
    "    sjer_reflectance_array = sjer_reflectance['Reflectance_Data']\n",
    "    reflectance_shape = sjer_reflectance_array.shape\n",
    "    wavelengths = sjer_reflectance['Metadata']['Spectral_Data']['Wavelength']\n",
    "    sjer_mapInfo = sjer_reflectance['Metadata']['Coordinate_System']['Map_Info']\n",
    "    mapInfo_string = str(sjer_mapInfo[()])\n",
    "    mapInfo_split = mapInfo_string.split(',') \n",
    "    res = float(mapInfo_split[5]), float(mapInfo_split[6])\n",
    "    xMin = float(mapInfo_split[3]) \n",
    "    yMax = float(mapInfo_split[4])\n",
    "    xMax = xMin + (reflectance_shape[1] * res[0])\n",
    "    yMin = yMax - (reflectance_shape[0] * res[1])\n",
    "    serc_ext = (xMin, xMax, yMin, yMax)\n",
    "    b56 = sjer_reflectance_array[:, :, 55].astype(float)\n",
    "    \n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    img = ax.imshow(b56, extent=serc_ext, cmap='jet')\n",
    "    ax.set_xlabel('Longitude', fontsize=16)\n",
    "    ax.set_ylabel('Latitude', fontsize=16)\n",
    "    plt.colorbar(img, label='Reflectance', ax=ax)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hyperspectral_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more indepth look at the HDF file structure is beyond the scope of this course. For those interested in learning more about HDF, Python, and hyperspectral data, check out the excellent resources from \n",
    "[The National Science Foundation's National Ecological Observatory Network (NEON)](https://www.neonscience.org/neon-aop-hdf5-py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section6'></a>\n",
    "## 6. APIs\n",
    "The term API is an acronym, and it stands for **Application Programming Interface**. An API is a software intermediary that allows two applications to talk to each other. APIs provide a means of collecting data with certain advantages over the file formats previously discussed. When would we want to use an API instead of a static CSV file you can download from the web?\n",
    "1. When you only want a small piece of a much larger dataset. For example, Donald Trump likes to Tweet alot. If you're only interested in Trump's Tweets from the last 12 hours, the Twitter API will save you from having to download all of Trump's Tweets and then searching the ones you're interested in.\n",
    "2. When the data is changing quickly. For example, if you're trying to build a high frequency trading alogrithm for the stock market, you're algorithm is going to need access to \"real-time\" data. Stock Exchange APIs can provide this kind of \"real-time\" data.\n",
    "3. When the API provides some kind of computational functionality that you need for your analysis. For example, you might be interested in using drone imagery to estimate the rooftop solar potential in your neighbourhood. To to this, you need to be able to segment the rooftops in an image from their surrounding background. Perhaps a research group has made their Machine Learning rooftop segmentation model available via an API endpoint. In this case, you could send the API a JPEG and get back a rooftop mask.\n",
    "\n",
    "#### How does an API work?\n",
    "An API runs on a remote server typically use HTTP as their transfer protocol. You can send data to an API and also retrive data, which will be the focus of thus Lecture. We use APIs all the time, probably without knowing it. For example, if you click on this link [FiveThirtyEight](https://fivethirtyeight.com/) (cool website, check it out) your web browser (Chrome, Explorer, Firefox, Safari) will make a request to get the webpage data so it can display it for you.\n",
    "<br>\n",
    "<img src=\"images/API.png\" alt=\"drawing\" width=\"600\"/>\n",
    "<br>\n",
    "There are many different types of requests that you can make, such as: GET, POST, PUT, DELETE, HEAD, OPTIONS, but for this lecture, we'll explore the GET requet. The diagram above presents the basic function of a GET request. We send information to the API specifying what data we want and the API will return the data we request and a response code indicating the status of the request. \n",
    "\n",
    "Common response codes:\n",
    "- **200 (OK)** | Indicates that the API successfully carried out whatever action the client requested.\n",
    "- **400 (Bad Request)** | The generic client-side error status indicating that you messed something up with your request. Check for errors in your code and try again.\n",
    "- **500 (Internal Server Error)** Something send wrong on the server side and is not the client’s fault. It is reasonable for the client to retry the same request that triggered this response and hope to get a different response.\n",
    "\n",
    "You can learn more about status codes [here](https://restfulapi.net/http-status-codes/).\n",
    "\n",
    "As an example, consider the Foreign exchange rates API **https://exchangeratesapi.io/**. Do do this programmatically in Python, we'll be using the **requests** package that was imported at the start of the Notebook.\n",
    "\n",
    "```Python\n",
    "import requests\n",
    "```\n",
    "\n",
    "For documentation explaining the APIs functionality, check out this [link](https://exchangeratesapi.io/).\n",
    "\n",
    "Let's try getting current exchange rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_key = '0cef27412b30145ee895a37d5d55cf9d'\n",
    "url = 'http://api.exchangeratesapi.io/v1/latest?access_key={}'.format(access_key)\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that a response contains the data we requested and the response code. Lets first check the repsonse code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Success! The request was successful. Let's see what response code we get it the url has a typo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://api.exchangeratesapi.io/v1/lates?access_key={}'.format(access_key)\n",
    "response = requests.get(url)\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bad request!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://api.exchangeratesapi.io/v1/latest?access_key={}'.format(access_key)\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so we got a 200 response, so now let's check out what data we got back.\n",
    "\n",
    "We can get the data as text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get the data as a JSON converted to a Python Dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use our ```json_print()``` function from earlier to see a more structured view of the JSON data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_print(obj):\n",
    "    text = json.dumps(obj, sort_keys=True, indent=4)\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the base rate is the Euro (EUR) but we can specify a base rate using the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://api.exchangeratesapi.io/v1/latest?access_key={}'.format(access_key)\n",
    "\n",
    "response = requests.get(url)\n",
    "json_print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section7'></a>\n",
    "## 7. HTML\n",
    "HTML stands for Hyper Text Markup Language and is the language that defines the structure of every webpage you visit. Most browsers haver a builtin debug tool that will allow you to see the HTML associated with each webpage you visit. Checkout [the CivMin](https://civmin.utoronto.ca/) site and press F12 on your keyboard.\n",
    "\n",
    "Below is an example of some simple HTML.\n",
    "\n",
    "```html\n",
    "<html>\n",
    "    <head>\n",
    "        <title>\n",
    "            A Simple HTML Document\n",
    "        </title>\n",
    "    </head>\n",
    "    <body>\n",
    "        <p>This is a very simple HTML document</p>\n",
    "        <p>It only has two paragraphs</p>\n",
    "    </body>\n",
    "</html>\n",
    "```\n",
    "\n",
    "Text surrounded with `< >` are called `tags` and as you can see from the HTML above, there are manu different types of tags.\n",
    "\n",
    "- HTML tag: It is the root of the html document which is used to specify that the document is html. <br>\n",
    "  `<html> Statements... </html>` <br>\n",
    "- Head tag: Head tag is used to contain all the head element in the html file. It contains the title, style, meta, … etc tag. <br>\n",
    "  `<head> Statements... </head>` <br>\n",
    "- Body tag: It is used to define the body of html document. It contains image, tables, lists, … etc. <br>\n",
    "  `<body> Statements... </body>` <br>\n",
    "- Title tag: It is used to define the title of html document. <br>\n",
    " `<title> Statements... </title>` <br>\n",
    "- Heading tag: It is used to define the heading of html document. <br>\n",
    "  `<h1> Statements... </h1>` <br>\n",
    "  `<h2> Statements... </h2>` <br>\n",
    "  `<h3> Statements... </h3>` <br>\n",
    "  `<h4> Statements... </h4>` <br>\n",
    "  `<h5> Statements... </h5>` <br>\n",
    "  `<h6> Statements... </h6>` <br>\n",
    "- Paragraph tag: It is used to define paragraph content in html document. <br>\n",
    "  `<p> Statements... </p>` <br>\n",
    "- Anchor tag: It is used to link one page to another page. <br>\n",
    "  `<a href=\"...\"> Statements... </a>` <br>\n",
    "- List tag: It is used to list the content. <br>\n",
    "  `<li> Statements... </li>` <br>\n",
    "- Ordered List tag: It is used to list the content in a particular order. <br>\n",
    "  `<ol> Statements... </ol>` <br>\n",
    "- Unordered List tag: It is used to list the content without order. <br>\n",
    "  `<ul> Statements... </ul>`\n",
    "  \n",
    "Let's first check out a very simple webpage. Remember the NOAA file we worked with in [Seciton 2: Unstructured Text Data](#section2)? This [website](https://www.glerl.noaa.gov/emf/waves/GLERL-Donelan-Archive/2021/) contains forecast files and measurements for Wave parameters such as heigh and direction. Let's say we want to analysis this data and need a way to programmatically extract the download links for all Wave Height forcast files. The HTML on this webpage looks like this (Go to the webpage and hit F12 to check it our for yourself).\n",
    "\n",
    "```html\n",
    "<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 3.2 Final//EN\">\n",
    "<html>\n",
    " <head>\n",
    "  <title>Index of /emf/waves/GLERL-Donelan-Archive/2021</title>\n",
    " </head>\n",
    " <body>\n",
    "  <h1>Index of /emf/waves/GLERL-Donelan-Archive/2021</h1>\n",
    "  <table>\n",
    "   <tbody>   \n",
    "    <tr></tr>\n",
    "    <tr></tr>\n",
    "    <tr></tr> \n",
    "    <tr>\n",
    "     <td></td>\n",
    "     <td></td>\n",
    "     <td>2021-02-23 06:12</td>  \n",
    "     <td>67M</td>\n",
    "     <td></td>   \n",
    "    </tr>\n",
    "```\n",
    "\n",
    "Let's introduce a useful Python package for scraping HTML. It's called `BeautifulSoup` and we imported it at the start of the notebook.\n",
    "\n",
    "```python\n",
    "from bs4 import BeautifulSoup\n",
    "```\n",
    "\n",
    "First, we need to use the webpage content using the `requests.get()` function we used in the last section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "response = requests.get('https://www.glerl.noaa.gov/emf/waves/GLERL-Donelan-Archive/2021/')\n",
    "response.text[0:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll use BeautifulSoup to parse the HTML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we want to extract table rows where a wave forecast file is linked. \n",
    "\n",
    "```html\n",
    "<tr>\n",
    "    <td valign=\"top\">\n",
    "     <img alt=\"[   ]\" src=\"/icons/unknown.gif\"/>\n",
    "    </td>\n",
    "    <td>\n",
    "     <a href=\"c2021_01.out1.nc\">\n",
    "      c2021_01.out1.nc\n",
    "     </a>\n",
    "    </td>\n",
    "    <td align=\"right\">\n",
    "     2021-02-23 06:12\n",
    "    </td>\n",
    "    <td align=\"right\">\n",
    "     67M\n",
    "    </td>\n",
    "    <td>\n",
    "    </td>\n",
    "</tr>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use BeautifulSoup to find all the `<tr>` tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_rows = soup.findAll('tr')\n",
    "print('{}\\n'.format(table_rows[0]))\n",
    "print('{}\\n'.format(table_rows[1]))\n",
    "print('{}\\n'.format(table_rows[2]))\n",
    "print('{}\\n'.format(table_rows[3]))\n",
    "print('{}\\n'.format(table_rows[4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the table data `<td>` we're interested in only appears after line 3 so let's grab everything from the 4th row on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_rows = table_rows[3:-1]\n",
    "print('{}\\n'.format(table_rows[0]))\n",
    "print('{}\\n'.format(table_rows[1]))\n",
    "print('{}\\n'.format(table_rows[2]))\n",
    "print('{}\\n'.format(table_rows[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within a row, how can we find the `<td></td>` tags?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_rows[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, how can we find the file name?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_rows[0].findAll('td')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_rows[0].findAll('td')[1].findAll('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_rows[0].findAll('td')[1].findAll('a')[0].contents"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
